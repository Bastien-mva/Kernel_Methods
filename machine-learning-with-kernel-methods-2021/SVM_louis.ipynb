{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "conditional-farmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvxopt\n",
      "  Downloading cvxopt-1.2.6-cp37-cp37m-win_amd64.whl (9.5 MB)\n",
      "Installing collected packages: cvxopt\n",
      "Successfully installed cvxopt-1.2.6\n"
     ]
    }
   ],
   "source": [
    "#!pip install qpsolvers\n",
    "#!pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supposed-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg\n",
    "from tqdm import tqdm\n",
    "import numba \n",
    "from numba import njit, vectorize, jit\n",
    "import time \n",
    "import scipy\n",
    "\n",
    "import qpsolvers\n",
    "from qpsolvers import solve_qp\n",
    "from qpsolvers import dense_solvers, sparse_solvers\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "import cvxopt\n",
    "import cvxopt.solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strange-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/Xtr0_mat100.csv',delimiter= ' ', header= None)\n",
    "Y_train = pd.read_csv('data/Ytr0.csv',delimiter= ',')\n",
    "X_test = pd.read_csv('data/Xte0_mat100.csv',delimiter= ' ', header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorporated-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.values\n",
    "Y = Y_train['Bound'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "transsexual-performer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "mobile-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def GaussianKernel(x, y, sig2 = 1): \n",
    "    return np.exp(-numpy.linalg.norm(x-y)**2/(2*sig2))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(x, y, p=5):\n",
    "    return (1 + np.dot(x, y)) ** p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "demonstrated-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.203829526901245 s\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "Kernel = np.apply_along_axis(lambda x1: np.apply_along_axis( lambda x2 : GaussianKernel(x2, x1), 1, X), 1, X)\n",
    "time2 = time.time()\n",
    "print(time2 - time1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "important-heater",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.98475818 0.98371162 ... 0.98848832 0.98942306 0.98895558]\n",
      " [0.98475818 1.         0.9799995  ... 0.98545651 0.98173781 0.97988373]\n",
      " [0.98371162 0.9799995  1.         ... 0.97826428 0.98196982 0.97699373]\n",
      " ...\n",
      " [0.98848832 0.98545651 0.97826428 ... 1.         0.98708787 0.98545651]\n",
      " [0.98942306 0.98173781 0.98196982 ... 0.98708787 1.         0.98650493]\n",
      " [0.98895558 0.97988373 0.97699373 ... 0.98545651 0.98650493 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Kernel)\n",
    "\n",
    "x_train = X[:1900]\n",
    "y_train = Y[:1900]\n",
    "x_val = X[1900:]\n",
    "y_val = Y[1900:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-breach",
   "metadata": {},
   "source": [
    "J'ai fais 2 SVM avec deux technique différentes, et ils donnent des résultats différent, SVM_1 j'ai remplacé alpha*Y pas beta et minimisé par rapport à beta, et SVM_1 c'est le normal comme la formule du cours. Je pense que SVM_2 a des résultats plus logiques, faut prendre C=5 environ.\n",
    "\n",
    "Au début j'ai voulu faire la méthode du cours mais rien marchait, je me suis donc inspiré d'un truc sur github où ils utilisaient le changement de variable avec beta donc j'ai fais ça, ce qui marche mais semble étrange. Après j'ai réessayé la méthode du cours (SVM_2) et ça fonctionne aussi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fatty-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avec cvxopt pour résoudre min_b 1/2 * b.T * diag(Y) * K * diag(Y) * b - b.T * 1 s.t. 0<= b <= C  \n",
    "#(en gros b= alpha * diag(Y))\n",
    "class SVM_1:\n",
    "    def __init__(self, kernel = GaussianKernel, C = 1):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.alpha = None\n",
    "        self.support_vectors = None\n",
    "        self.support_Y = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        #calculate the kernel\n",
    "        K = np.apply_along_axis(lambda x1: np.apply_along_axis( lambda x2 : self.kernel(x2, x1), 1, X), 1, X)\n",
    "        \n",
    "        n = len(Y)\n",
    "        lbd = 1\n",
    "        #C = 1 / (2 * n * lbd)  #ça dépend si on veut gérer C ou lambda\n",
    "\n",
    "        #take Y as -1 and 1\n",
    "        label = 2 * Y - 1\n",
    "        \n",
    "        \n",
    "        P = cvxopt.matrix(np.outer(label, label) * K ) \n",
    "        q = cvxopt.matrix(-np.ones(n))\n",
    "        A = cvxopt.matrix(label, (1,n), 'd')\n",
    "        b = cvxopt.matrix(0.0)\n",
    "                \n",
    "        '''Je réécris l'inégalité : 0<=y_i*alpha_i<=C avec C = 1/(2*lambda*n)\n",
    "        comme: G*alpha<=h avec G=stack(diag(Y),-diag(Y)) et h= [C, ..., C, 0, ..., 0] (n fois C et n fois 0)\n",
    "        ça revient au même et je crois que le solver devrait fonctionner avec ça, mais j'y arrive pas encore\n",
    "        '''\n",
    "        # b <= C\n",
    "        G1 = np.eye(n)\n",
    "        h1 = np.ones(n) * self.C\n",
    "        \n",
    "        # -b <= 0\n",
    "        G2 = -np.eye(n)\n",
    "        h2 = np.zeros(n)\n",
    "        \n",
    "        G = cvxopt.matrix(np.vstack((G2, G1)))\n",
    "        h = cvxopt.matrix(np.hstack((h2, h1)))\n",
    "\n",
    "        #min_b 1/2 * b.T * diag(Y) * K * diag(Y) * b - b.T * 1 s.t. 0<= b <= C\n",
    "        solver = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        \n",
    "        self.alpha = np.ravel(solver['x'])\n",
    "        \n",
    "        #Je retire les vecteurs avec un alpha trop petit\n",
    "        eps = 1e-5\n",
    "        supportIndices = self.alpha > eps\n",
    "        ind = np.arange(n)[supportIndices]\n",
    "        \n",
    "        self.support_vectors = X[supportIndices]\n",
    "        self.support_Y = label[supportIndices]\n",
    "        self.alpha_ = self.alpha[supportIndices]  #alpha_ : alpha sans les alpha < eps\n",
    "        \n",
    "        #Bias\n",
    "        self.b = 0\n",
    "        for i in range(len(self.alpha_)):\n",
    "            self.b = self.support_Y[i]\n",
    "            self.b -= np.sum( self.alpha_ * self.support_Y * K[ind[i], supportIndices])\n",
    "        self.b /= len(self.alpha_)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_predict = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            for alpha, sv, label in zip(self.alpha_, self.support_vectors, self.support_Y):\n",
    "                y_predict[i] += alpha * label * self.kernel(sv, X[i]) \n",
    "        \n",
    "        return ((y_predict + self.b) > 0)*1\n",
    "        #return y_predict + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "sacred-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avec cvxopt pour résoudre min_a 1/2 * alpha.T * K * alpha - alpha.T * Y s.t. 0<=y*alpha<=C\n",
    "class SVM_2:\n",
    "    def __init__(self, kernel = GaussianKernel, C = 1):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.alpha = None\n",
    "        self.support_vectors = None\n",
    "        self.support_Y = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        K = np.apply_along_axis(lambda x1: np.apply_along_axis( lambda x2 : self.kernel(x2, x1), 1, X), 1, X)\n",
    "        \n",
    "        n = len(Y)\n",
    "        #lbd = 1\n",
    "        #C = 1 / (2 * n * lbd)  #ça dépend si on veut gérer C ou lambda\n",
    "\n",
    "        label = 2 * Y - 1\n",
    "        \n",
    "        # P=K et q=-Y\n",
    "        P = cvxopt.matrix(K) \n",
    "        q = cvxopt.matrix(-label, tc='d')\n",
    "                \n",
    "        '''Je réécris l'inégalité : 0<=y_i*alpha_i<=C avec C = 1/(2*lambda*n)\n",
    "        comme: G*alpha<=h avec G=stack(diag(Y),-diag(Y)) et h= [C, ..., C, 0, ..., 0] (n fois C et n fois 0)\n",
    "        '''\n",
    "        \n",
    "        # Condition 0 <= alpha_i * Y_i <= C\n",
    "        G1 = np.diag(-label)\n",
    "        G2 = np.diag(label)\n",
    "        G = cvxopt.matrix(np.vstack((G1, G2)), tc='d')\n",
    "        \n",
    "        h1 = np.zeros((n, 1), dtype='float64')\n",
    "        h2 = self.C * np.ones((n, 1), dtype='float64')\n",
    "        h = cvxopt.matrix(np.vstack((h1, h2)))\n",
    "\n",
    "        # solves min_a 1/2 a^T * P * a + q^T * a s.t. G*a <= h\n",
    "        solver = cvxopt.solvers.qp(P, q, G, h)\n",
    "        \n",
    "        self.alpha = np.ravel(solver['x'])\n",
    "        \n",
    "        #Je retire les vecteurs avec un alpha trop petit\n",
    "        eps = 1e-5\n",
    "        supportIndices = np.abs(self.alpha) > eps\n",
    "        ind = np.arange(n)[supportIndices]\n",
    "        \n",
    "        self.support_vectors = X[supportIndices]\n",
    "        self.support_Y = label[supportIndices]\n",
    "        self.alpha_ = self.alpha[supportIndices]  #alpha_ : alpha sans les alpha < eps\n",
    "        \n",
    "        #Bias\n",
    "        self.b = 0\n",
    "        for i in range(len(self.alpha_)):\n",
    "            self.b = self.support_Y[i]\n",
    "            self.b -= np.sum( self.alpha_ * K[ind[i], supportIndices])\n",
    "        self.b /= len(self.alpha_)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_predict = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            for j in range(len(self.alpha_)):\n",
    "                y_predict[i] += self.alpha_[j] * self.kernel(self.support_vectors[j], X[i])\n",
    "        \n",
    "        return ((y_predict + self.b) > 0)*1\n",
    "        #return y_predict + self.b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "social-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVM_2(kernel = GaussianKernel, C=5)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "results = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "spanish-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0] [1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
      " 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "56\n",
      "[-0.99999995  0.99999995  0.99999996 ... -0.9999999  -0.99999994\n",
      "  0.99999995] 1809 0.0007539632839989708\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(x_val)\n",
    "print( results, y_val)\n",
    "n = results == y_val\n",
    "print(sum(n))\n",
    "print(model.alpha, len(model.alpha_), model.b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-service",
   "metadata": {},
   "source": [
    "EN dessous il y a un autre avec la même méthode que 'SVM_1' mais avec un autre optimiseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "beginning-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avec qp_solver pour résoudre min_b 1/2 * b.T * diag(Y) * K * diag(Y) * b - b.T * 1 s.t. 0<= b <= C  \n",
    "#(en gros b= alpha * diag(Y))\n",
    "\n",
    "#Il marche et donne le même résultat que cvxopt\n",
    "\n",
    "class SVM_autre:\n",
    "    def __init__(self, kernel=GaussianKernel, C=1):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.alpha = None\n",
    "        self.support_vectors = None\n",
    "        self.support_Y = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        K = np.apply_along_axis(lambda x1: np.apply_along_axis( lambda x2 : self.kernel(x2, x1), 1, X), 1, X)\n",
    "        \n",
    "        n = len(Y)\n",
    "        lbd = 1\n",
    "        #C = 1 / (2 * n * lbd)  #ça dépend si on veut gérer C ou lambda\n",
    "\n",
    "        label = 2 * Y - 1\n",
    "        \n",
    "        P = np.outer(label, label) * K\n",
    "        q = - np.ones(n)\n",
    "        \n",
    "        '''Je réécris l'inégalité : 0<=y_i*alpha_i<=C avec C = 1/(2*lambda*n)\n",
    "        comme: G*alpha<=h avec G=stack(diag(Y),-diag(Y)) et h= [C, ..., C, 0, ..., 0] (n fois C et n fois 0)\n",
    "        ça revient au même et je crois que le solver devrait fonctionner avec ça, mais j'y arrive pas encore\n",
    "        '''\n",
    "        G = np.vstack((np.eye(n), -np.eye(n)))\n",
    "\n",
    "        h = np.ones(2*n)\n",
    "        h[:n] = h[:n] * self.C\n",
    "        h[n:] = h[n:] * 0\n",
    "\n",
    "        A = label\n",
    "        b = np.array([0.])\n",
    "\n",
    "        self.alpha = solve_qp(P, q.astype('double'), G.astype('double'), h, A, b, solver = 'quadprog')\n",
    "        \n",
    "        #Pour le moment je garde tout X mais faudrait retirer les X dont le alpha est trop bas\n",
    "        eps = 1e-15\n",
    "        supportIndices = self.alpha > eps\n",
    "        ind = np.arange(n)[supportIndices]\n",
    "        \n",
    "        self.support_vectors = X[supportIndices]\n",
    "        self.support_Y = label[supportIndices]\n",
    "        self.alpha_ = self.alpha[supportIndices]\n",
    "        \n",
    "        #Bias\n",
    "        self.b = 0\n",
    "        for i in range(len(self.alpha_)):\n",
    "            self.b = self.support_Y[i]\n",
    "            self.b -= np.sum( self.alpha_ * self.support_Y * K[ind[i], supportIndices])\n",
    "        self.b /= len(self.alpha_)\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        y_predict = np.zeros(len(X))\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            for alpha, sv, label in zip(self.alpha_, self.support_vectors, self.support_Y):\n",
    "                y_predict[i] += alpha * label * self.kernel(sv, X[i]) \n",
    "\n",
    "        return ((y_predict + self.b) > 0)*1\n",
    "    \n",
    "    def predict_bis(self, X):\n",
    "        \n",
    "        def predict_one(x):\n",
    "            pred = np.apply_along_axis(lambda s: self.kernel(s, x), 1, self.support_vectors)\n",
    "            pred = pred * self.support_Y * self.alpha\n",
    "            return np.sum(pred)\n",
    "        \n",
    "        preds = np.apply_along_axis(predict_one, 1, X)\n",
    "        return 1 * (preds > 0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "funky-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm = SVM_autre(kernel = GaussianKernel)\n",
    "svm.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "controlling-trouble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0] [1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
      " 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "results = svm.predict(x_val)\n",
    "print(results, y_val)\n",
    "print(svm.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-simpson",
   "metadata": {},
   "source": [
    "Aide svm github : https://github.com/zongmianli/mva-kernel-methods/blob/kernel-challenge/svm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "antique-fishing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02414692  0.00498681  0.01534296  0.03327065  0.02499289  0.01782278\n",
      "  0.00641423  0.01737927  0.00571243  0.03785679  0.02937389 -0.0020743\n",
      "  0.01801311  0.01202195  0.02616614  0.02493651  0.02069579  0.00564455\n",
      " -0.00066408  0.02225113  0.00237909  0.03542867  0.00787691  0.02247312\n",
      "  0.02751154  0.00633758  0.01760011  0.0165434   0.0267509   0.03206684\n",
      "  0.01438477  0.03242849  0.01270201  0.01455076  0.00451208  0.01183673\n",
      "  0.01354231  0.00326173  0.04398204  0.02790272 -0.00445432  0.04707981\n",
      "  0.00802263  0.02043321  0.00878177  0.01557869  0.03094886  0.03406918\n",
      "  0.02125684  0.02878366  0.00324311  0.01825782  0.02390436  0.00269406\n",
      "  0.02602237  0.01234005  0.00085998  0.0158754   0.02489576  0.02026007\n",
      "  0.00903557  0.0151773   0.03625054  0.01268538  0.00022868  0.00617082\n",
      "  0.0134089   0.01244844 -0.00563212  0.00012831  0.02412231  0.02177587\n",
      "  0.01969552  0.03197964  0.01770224  0.01614737  0.01016502  0.03356141\n",
      "  0.00210028  0.02871426  0.00812573 -0.00372503  0.02350311  0.03760823\n",
      "  0.01724742  0.01470091  0.0336364   0.02919009  0.02509313  0.00788259\n",
      "  0.0071019   0.00382853  0.03857615  0.01813762  0.00941578 -0.00600826\n",
      "  0.02025118  0.0257626   0.0119341  -0.00116485] [1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
      " 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0] [179.53299291473328, 179.2638193446423, 180.06224292004032, 179.98659862549744, 180.16655562663908, 179.22562567027808, 179.75516827499877, 179.66681955881654, 180.18673038466085, 179.70241921540344, 179.75791492680966, 180.00640157214227, 179.74911107109548, 179.44817542047855, 179.7850907331536, 179.5778626028203, 179.5496336538501, 179.8592049366436, 174.77746331094124, 179.59672640457802, 178.35988857531692, 179.8078495329257, 179.31872034329956, 180.07631170977538, 179.578343086164, 179.39241844112905, 180.2470769371597, 179.74626811428834, 179.2629305887961, 179.56186642155092, 180.12031700199594, 179.73210576965843, 179.49982565165803, 179.97592902073393, 179.95039953989735, 179.788659581134, 179.775622431027, 180.20588015176787, 179.3612256550765, 179.7158465553939, 179.2436108196129, 179.31601944226543, 179.26289857068903, 180.05071604001594, 180.0069337865176, 179.98289655308085, 179.79608566334838, 180.04765977314327, 179.84502724551533, 179.88596317123944, 178.68342513554018, 179.87434479060593, 180.02386270412558, 179.6190805627739, 177.7993652170307, 180.01741078269117, 180.094808334175, 180.06057382875395, 179.74661948524238, 179.86970409796655, 179.71353103963804, 180.14250582326866, 179.96612741819962, 180.03915165612278, 179.50714427689144, 180.0398283532452, 179.9683182002998, 179.55131704933473, 179.9211668447428, 179.88145303643572, 179.87976394730816, 179.63064625853465, 179.8714339296601, 179.5202150128781, 178.89877277044604, 179.99463301154293, 179.58198307647763, 179.7409697119273, 179.1261397883086, 179.39255188559272, 179.7519504616132, 179.87882035781223, 180.1244229738326, 179.77478119935347, 180.02566561893596, 179.71273049858195, 179.47839684275363, 179.92173758422285, 179.6568178309584, 180.17560952157513, 179.45673093356072, 179.8877368182291, 179.70823779075891, 180.1933542168511, 179.85672035873722, 179.7460786341896, 179.71641059675997, 179.468887095894, 179.7800981991421, 179.69958266160398]\n"
     ]
    }
   ],
   "source": [
    "#Tests sur les fct de prédiction\n",
    "\n",
    "def predict_one(x):\n",
    "    pred = np.apply_along_axis(lambda s: GaussianKernel(s, x), 1, X_bis)\n",
    "    pred = pred * Y_bis * model.alpha\n",
    "    return np.sum(pred)\n",
    "\n",
    "def f_from_alpha(alpha, Kernel, X):\n",
    "    return  lambda x : np.sum([alpha[i]*Kernel(X[i,:],x) for i in range(X.shape[0])])\n",
    "f_alpha = f_from_alpha(model.alpha, GaussianKernel, x_train)\n",
    "\n",
    "res = [f_alpha(x_val[i]) for i in range(len(y_val))]\n",
    "\n",
    "preds = np.apply_along_axis(predict_one, 1, x_val)\n",
    "#preds = 1 * (preds > 0)\n",
    "print(preds, y_val, res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
