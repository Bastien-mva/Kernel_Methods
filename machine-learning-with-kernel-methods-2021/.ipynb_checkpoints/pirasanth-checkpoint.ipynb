{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "connected-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from numba import njit\n",
    "import numpy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "correct-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/Xtr0_mat100.csv', header=None, delimiter = ' ').to_numpy()\n",
    "y_train = pd.read_csv('data/Ytr0.csv')['Bound'].to_numpy()\n",
    "#y_train = 2*y_train-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "popular-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Kernel Logestic Regression -- Kernel Methods for Machine Learning 2017-2018 -- RATNAMOGAN Pirashanth -- SAYEM Othmane\n",
    "This file contains our implementation of the kernel logestic regression\n",
    "'''\n",
    "\n",
    "import numpy as np \n",
    "import math\n",
    "#import seaborn as sns\n",
    "#from Utils import *\n",
    "\n",
    "###########\"Définition de fonctions simples mais utilisés fréquemment\n",
    "sigmoid = lambda x: 1./(1+np.exp(-x)) # sigmoid\n",
    "eta = lambda x,w: sigmoid(np.dot(w.transpose(),x)) #fonction eta du rapport\n",
    "inverse_sigmoid = lambda x: math.log(1/x-1)  #inverse de la sigmoid\n",
    "#####################################################################\n",
    "\n",
    "'''\n",
    "All the following functions are intermed calculus that appears in the IRLS algorithm computation\n",
    "One can see the slides about Kernel logestic Regression (slide 105-111 in the MVA Kernel Methods for Machine Learning\n",
    "class)\n",
    "'''\n",
    "def compute_m(p_Kernel_Mat,p_alpha):\n",
    "    return p_Kernel_Mat.dot(p_alpha)\n",
    "\n",
    "def compute_P(p_y,p_m):\n",
    "    return np.diag( -sigmoid(-p_y*p_m)[:,0])\n",
    "\n",
    "def compute_W(p_y,p_m):\n",
    "    diag_compo = sigmoid(p_y*p_m)\n",
    "    diag_compo = diag_compo*(1-diag_compo) \n",
    "    return np.diag(diag_compo[:,0])\n",
    "\n",
    "def compute_Z(p_m,p_y):\n",
    "    z= p_m+p_y/sigmoid(-p_y*p_m)\n",
    "    return z\n",
    "\n",
    "def compute_alpha(p_Kernel,p_W,p_z,lambda_reg):\n",
    "    W_12 = np.sqrt(p_W)\n",
    "    n = p_Kernel.shape[0]\n",
    "    to_inv = W_12.dot(p_Kernel).dot(W_12)+n*lambda_reg*np.eye(n)\n",
    "    to_inv = np.linalg.inv(to_inv)\n",
    "    alpha = W_12.dot(to_inv).dot(W_12).dot(p_z)\n",
    "    return alpha\n",
    "\n",
    "class KernelLogisticRegression:\n",
    "    '''\n",
    "    Class KernelLogisticRegression: create a kernel logestic regression binary classifier\n",
    "    Attributes: - alpha_ : alpha parameter (that appears because of the representer theorem)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,init_coef=0):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        if init_coef==0:\n",
    "            self.alpha_ = 0\n",
    "    \n",
    "    def fit(self,kernel_train,label,alpha=None,tolerance=1,lambda_regularisation=0):\n",
    "        '''\n",
    "        Fonction fit: Compute the IRLS algorithm in order to learn the parameters\n",
    "        Paramaters: kernel_train: (np.array(nb_samples,nb_samples)) gram training matrix\n",
    "                    label: (np.array(nb_samples,)) true labels of the samples\n",
    "                    coef_old:np.array(nb_composante,1) old coefficients before update\n",
    "                    tolerance: const, stopping criteria\n",
    "                    lambda_regularisation: 0=<const=<1 regularization parameter\n",
    "        Return: The new learned parameters\n",
    "        '''  \n",
    "        ### matrice diagonale\n",
    "        size_changed=False\n",
    "        if label.ndim==1:\n",
    "            label.resize([label.shape[0],1])\n",
    "            size_changed = True\n",
    "        \n",
    "        if np.array((alpha==None)).any():\n",
    "            alpha = np.random.rand(kernel_train.shape[0],1)\n",
    "        \n",
    "        old_alpha = np.array(alpha)\n",
    "        m = compute_m(kernel_train,alpha)\n",
    "        P = np.nan_to_num(compute_P(label,m))\n",
    "        W = np.nan_to_num(compute_W(label,m))\n",
    "        z = compute_Z(m,label)\n",
    "        alpha = compute_alpha(kernel_train,W,z,lambda_regularisation)\n",
    "        #print(alpha)\n",
    "        if size_changed:\n",
    "            label.resize([label.shape[0],])\n",
    "        #print(sum(label*np.log(eta(data.transpose(),coef_old))[0]) + sum((1-label)*np.log(eta(data.transpose(),-coef_old))[0]))\n",
    "        print(np.linalg.norm(alpha-old_alpha))\n",
    "        print('bool :', np.linalg.norm(alpha-old_alpha))\n",
    "        if (np.linalg.norm(alpha-old_alpha)>tolerance):\n",
    "            \n",
    "            self.fit(kernel_train,label,alpha,tolerance,lambda_regularisation)\n",
    "        else:\n",
    "            self.alpha_=alpha\n",
    "    \n",
    "    def get_coef(self):\n",
    "        '''\n",
    "        get_coef: Return the alpha parameter of the class\n",
    "        Paramaters: -\n",
    "        Return: the model parameters\n",
    "        '''\n",
    "        return list(self.alpha_)\n",
    "\n",
    "    def predict(self,kernel_test):\n",
    "        '''\n",
    "        predict: give the probability to obtain the label y=1 for the given data\n",
    "        Paramaters: - kernel_test : (np.array(nb_samples_train,nb_sample_test)) test gram matrix\n",
    "        Return: probabilities associated to each data in the data matrix as  a np.array\n",
    "        '''\n",
    "        prediction = ((self.alpha_.T.dot(kernel_test)).T).reshape(-1)\n",
    "        prediction= sigmoid(prediction).reshape(-1)\n",
    "        return prediction\n",
    "    \n",
    "    def predict_class(self,kernel_test):\n",
    "        '''\n",
    "        predict_class: Predict the label for a given set of data\n",
    "        Paramaters: - kernel_test : (np.array(nb_samples_train,nb_sample_test)) test gram matrix\n",
    "        Return: labels\n",
    "        '''\n",
    "        prediction = np.array(self.predict(kernel_test)>=0.5,dtype=int)\n",
    "        prediction[prediction ==0]=-1\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "alive-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def GaussianKernel(x,y,sig2 = 1): \n",
    "    return np.exp(-numpy.linalg.norm(x-y)**2/(2*sig2))\n",
    "\n",
    "@njit\n",
    "def to_mat_K(X, Kernel, sig2 = 1): \n",
    "    length = X.shape[0]\n",
    "    mat_K = np.zeros((length,length))\n",
    "    for i in range(length):\n",
    "        x_i = X[i,:]\n",
    "        for j in range(i,length): \n",
    "            x_j = X[j,:]\n",
    "            value = Kernel(x_i,x_j,sig2)\n",
    "            mat_K[i,j] = value\n",
    "            mat_K[j,i] = value \n",
    "    return mat_K     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "asian-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_K = to_mat_K(X_train,GaussianKernel, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "functioning-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-98ec162e9531>:12: RuntimeWarning: overflow encountered in exp\n",
      "  sigmoid = lambda x: 1./(1+np.exp(-x)) # sigmoid\n",
      "<ipython-input-29-98ec162e9531>:34: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z= p_m+p_y/sigmoid(-p_y*p_m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "bool : nan\n"
     ]
    }
   ],
   "source": [
    "KRL = KernelLogisticRegression()\n",
    "KRL.fit(mat_K,y_train,lambda_regularisation=0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-patrol",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
