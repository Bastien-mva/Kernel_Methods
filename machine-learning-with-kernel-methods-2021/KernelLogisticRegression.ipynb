{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg \n",
    "from tqdm import tqdm\n",
    "import numba\n",
    "from numba import njit,vectorize, jit\n",
    "import time\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "streaming-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/Xtr0_mat100.csv', header=None, delimiter = ' ').to_numpy()\n",
    "y_train = pd.read_csv('data/Ytr0.csv')['Bound'].to_numpy()\n",
    "y_train = 2*y_train-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "apparent-rogers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bastien/Documents/ENS/KM/Kernel_Methods/machine-learning-with-kernel-methods-2021\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "funded-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def GaussianKernel(x,y,sig2 = 1):\n",
    "    return np.exp(-numpy.linalg.norm(x-y)**2/(2*sig2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "respective-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def f_for_data(alpha,mat_K,j): \n",
    "    return np.sum([alpha[i]*mat_K[i,j] for i in range(mat_K.shape[0])])\n",
    "\n",
    "def f_from_alpha(alpha, Kernel, X):\n",
    "    '''\n",
    "    Calcule f à partir d'alpha. On utilise ici la forumule du representer thm : \n",
    "    f(x) = sum(alpha_i*K(x_i,x))\n",
    "    \n",
    "    args : \n",
    "        alpha : vecteur de taille (nombre de données dans le dataset). \n",
    "        Kernel : n'importe quel kernel \n",
    "        X : Matrice contenant les données. X.shape[0] doit etre eégal à la taille de alpha\n",
    "        \n",
    "    return : la fonction donnée par le representer theorem\n",
    "    '''\n",
    "    return  lambda x : np.sum([alpha[i]*(Kernel(X[i,:],x)) for i in range(X.shape[0])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aboriginal-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def to_mat_K(X, Kernel, sig2 = 1): \n",
    "    length = X.shape[0]\n",
    "    mat_K = np.zeros((length,length))\n",
    "    for i in range(length):\n",
    "        x_i = X[i,:]\n",
    "        for j in range(i,length): \n",
    "            x_j = X[j,:]\n",
    "            value = Kernel(x_i,x_j,sig2)\n",
    "            mat_K[i,j] = value\n",
    "            mat_K[j,i] = value \n",
    "    return mat_K\n",
    "\n",
    "lam = 0\n",
    "sig2 = 1\n",
    "alpha = np.ones(X_train.shape[0])\n",
    "mat_K = to_mat_K(X_train,GaussianKernel, 1)\n",
    "alpha_init = np.ones(mat_K.shape[0])/mat_K.shape[0]\n",
    "vect_W_init = np.ones(mat_K.shape[0])\n",
    "\n",
    "def standardize(K): \n",
    "    U = np.full(K.shape,1/K.shape[0])\n",
    "    I = np.eye(K.shape[0])\n",
    "    return (I-U)@K@(I-U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cutting-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@vectorize\n",
    "def loss(u): \n",
    "    return np.log(1+np.exp(-u))\n",
    "def sigmoid(u): \n",
    "    return 1/(1+np.exp(-u))\n",
    "\n",
    "\n",
    "def grad_loss(u): \n",
    "    return -sigmoid(-u)\n",
    "\n",
    "def hess_loss(u): \n",
    "    return sigmoid(u)*sigmoid(-u)\n",
    "\n",
    "def J(alpha, y = y_train, mat_K = mat_K, lam = lam):\n",
    "    n = alpha.shape[0]\n",
    "    regularizer = lam/2*alpha@mat_K@alpha\n",
    "    vect = mat_K@alpha\n",
    "    somme = 1/n*np.sum(loss(y*vect))\n",
    "    return somme+regularizer\n",
    "   \n",
    "def grad_J(alpha, y = y_train, mat_K = mat_K, lam = lam): \n",
    "    n = y.shape[0]\n",
    "    vect_P_alpha = grad_loss(y*(mat_K@alpha))\n",
    "    return 1/n*mat_K@(vect_P_alpha*y)+ lam*mat_K@alpha\n",
    "\n",
    "def hess_J(alpha, y = y_train, mat_K = mat_K, lam = lam):\n",
    "    n = mat_K.shape[0]\n",
    "    vect_W = hess_loss(y*(mat_K@alpha))\n",
    "    return 1/n*mat_K +lam*mat_K\n",
    "\n",
    "def Kernel_logistic_reg_fit(X= X_train, y = y_train, mat_K = mat_K, lam = lam, Niter =20):\n",
    "    alpha = 0.00000*np.random.randn(X.shape[0])\n",
    "    #alpha = np.ones(2000)\n",
    "    mat_K = standardize(mat_K)\n",
    "    lr = 5\n",
    "    for i in tqdm(range(Niter)): \n",
    "        #inv = np.linalg.inv(hess_J(alpha, mat_K = mat_K))\n",
    "        #alpha-= lr*inv@grad_J(alpha ,mat_K = mat_K)#, mat_K= mat_K)\n",
    "        alpha-= lr*grad_J(alpha ,mat_K = mat_K)\n",
    "        '''\n",
    "        if i%1 ==0 : \n",
    "            print('alpha :', alpha)\n",
    "            print('J :',J(alpha,mat_K = mat_K))\n",
    "            print('grad :', grad_J(alpha,mat_K = mat_K))\n",
    "    print('alpha_end :', alpha)\n",
    "    print('J_end :',J(alpha,mat_K = mat_K))\n",
    "    print('grad_end :', grad_J(alpha,mat_K = mat_K))'''\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hairy-indie",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5c399bd5f551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_from_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGaussianKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m' :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' y :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_alpha' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "f = f_from_alpha(first_alpha, GaussianKernel, X_train)\n",
    "for i in range(10): \n",
    "        print(i ,' :',np.round(f(X_train[i,:]),3), ' y :', y_train[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "helpful-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e-8 marche bien pour lambda\n",
    "def fit_KRR(mat_K,lam,y):\n",
    "    #mat_K = standardize(mat_K) #marche pas si on standardise \n",
    "    n = mat_K.shape[0]\n",
    "    full_mat = mat_K +n*lam*np.eye(n)\n",
    "    alpha = np.linalg.solve(full_mat,y)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "challenging-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef fit_WKRR(mat_K,vect_W, lam, y): \\n    # pour l'instant on suppose que W est bien inversible, i.e. aucune valeur à zéro\\n    n = mat_K.shape[0]\\n    mat_sqrt_W = np.diag(np.sqrt(vect_W))\\n    mat_neg_sqrt_W = np.diag(1/np.sqrt(vect_W))\\n    big_mat = mat_sqrt_W@mat_K@mat_sqrt_W + n*lam*np.eye(n)\\n    return scipy.linalg.solve(big_mat@mat_neg_sqrt_W,mat_sqrt_W@y)\\n\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meme fonction que WKRR, mais on est environ 10 fois plus lent\n",
    "'''\n",
    "def fit_WKRR(mat_K,vect_W, lam, y): \n",
    "    # pour l'instant on suppose que W est bien inversible, i.e. aucune valeur à zéro\n",
    "    n = mat_K.shape[0]\n",
    "    mat_sqrt_W = np.diag(np.sqrt(vect_W))\n",
    "    mat_neg_sqrt_W = np.diag(1/np.sqrt(vect_W))\n",
    "    big_mat = mat_sqrt_W@mat_K@mat_sqrt_W + n*lam*np.eye(n)\n",
    "    return scipy.linalg.solve(big_mat@mat_neg_sqrt_W,mat_sqrt_W@y)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "disciplinary-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_WKRR(mat_K,vect_W,lam,y): \n",
    "    '''\n",
    "    Compute the Weighted Kernel Redge Regression. the Formula is given in the course. \n",
    "    The code is optimized, we do not take the diagonal matrix of the square root of W. Instead, \n",
    "    we only compute some np.multiply stuff. \n",
    "    \n",
    "    args : \n",
    "    \n",
    "            mat_K : Kernel Matrix that contains the information in the data (K_ij=K(x_i,x_j))\n",
    "            vect_W : the vector that contains the weight associated to each sample. here we need that all the \n",
    "            coefficient of this vector is 0. Otherwise we won't be able to compute the inverse of the square root\n",
    "            lam : regularization factor \n",
    "            y : the vector we train on \n",
    "    \n",
    "    returns :\n",
    "            \n",
    "            the vector alpha that satisfy the formula in the course. \n",
    "    alpha then needs to be transformed to a function in order to fit the data.\n",
    "    '''\n",
    "    min_W = np.min(vect_W)\n",
    "    if (min_W < 0) or (min_W == 0) : \n",
    "        print('Non invertible Matrix W ')\n",
    "    n = mat_K.shape[0]\n",
    "    vect_sqrt_W = np.sqrt(vect_W) # the square root of the original vector\n",
    "    vect_neg_sqrt_W = 1/vect_sqrt_W # the negative square root of the original vector\n",
    "    b = np.multiply(vect_sqrt_W,y) \n",
    "    big_mat = np.multiply(np.multiply(vect_sqrt_W.reshape(-1,1),mat_K), vect_sqrt_W) +n*lam*np.eye(n)\n",
    "    A = np.multiply(vect_neg_sqrt_W,big_mat)\n",
    "    return scipy.linalg.solve(A,b)\n",
    "\n",
    "vect_W_init = np.full(mat_K.shape[0],1)#/mat_K.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "boolean-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def IRLS(K, y, alpha):\n",
    "        \"\"\"\n",
    "        Iterative step to update alpha when training the classifier\n",
    "        :param K: np.array, kernel\n",
    "        :param y: np.array, labels\n",
    "        :param alpha: np.array\n",
    "        :return: - W: np.array\n",
    "                 - z: np.array\n",
    "        \"\"\"\n",
    "        m = np.dot(K, alpha)\n",
    "        W = sigmoid(m) * sigmoid(-m)\n",
    "        z = m + y/sigmoid(-y*m)\n",
    "        return W, z\n",
    "\n",
    "def WKRR_af(K, W, z):\n",
    "        \"\"\"\n",
    "        Compute new alpha\n",
    "        :param K: np.array, kernel\n",
    "        :param W: np.array\n",
    "        :param z: np.array\n",
    "        :return: np.array, new alpha\n",
    "        \"\"\"\n",
    "        n = K.shape[0]\n",
    "        W_s = np.diag(np.sqrt(W))\n",
    "        A = np.dot(np.dot(W_s, K), W_s) + n * lam * np.eye(n)\n",
    "        A = np.dot(np.dot(W_s, np.linalg.inv(A)), W_s)\n",
    "        return np.dot(A, z)\n",
    "    \n",
    "    \n",
    "def recoding_KRL(mat_K,lam,y, max_iter = 10): \n",
    "    n = mat_K.shape[0]\n",
    "    old_alpha = 0*np.ones(n)\n",
    "    for i in range(max_iter): \n",
    "        W,z = IRLS(mat_K,y,old_alpha)\n",
    "        alpha = fit_WKRR(mat_K, W, lam, z)\n",
    "        f = f_from_alpha(alpha, GaussianKernel, X_train)\n",
    "        old_alpha = np.copy(alpha)\n",
    "    return alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "interesting-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_m(mat_K,alpha): \n",
    "    return mat_K@alpha\n",
    "\n",
    "def compute_P(y,m): \n",
    "    return -sigmoid(-np.multiply(y,m))\n",
    "\n",
    "def compute_W(m):\n",
    "    return np.multiply(sigmoid(m),sigmoid(m))\n",
    "\n",
    "def compute_z(y,m): \n",
    "    return m + np.multiply(y,1/sigmoid(-np.multiply(y,m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sudden-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  : -2.0  y : -1\n",
      "1  : 2.0  y : 1\n",
      "2  : 2.0  y : 1\n",
      "3  : 2.0  y : 1\n",
      "4  : 2.0  y : 1\n",
      "5  : -2.0  y : -1\n",
      "6  : -2.0  y : -1\n",
      "7  : -2.0  y : -1\n",
      "8  : -2.0  y : -1\n",
      "9  : 2.0  y : 1\n",
      "0  : -10.389  y : -1\n",
      "1  : 10.389  y : 1\n",
      "2  : 10.389  y : 1\n",
      "3  : 10.389  y : 1\n",
      "4  : 10.389  y : 1\n",
      "5  : -10.389  y : -1\n",
      "6  : -10.389  y : -1\n",
      "7  : -10.389  y : -1\n",
      "8  : -10.389  y : -1\n",
      "9  : 10.389  y : 1\n",
      "0  : -32513.364  y : -1\n",
      "1  : 32513.359  y : 1\n",
      "2  : 32513.367  y : 1\n",
      "3  : 32513.361  y : 1\n",
      "4  : 32513.36  y : 1\n",
      "5  : -32513.363  y : -1\n",
      "6  : -32513.364  y : -1\n",
      "7  : -32513.365  y : -1\n",
      "8  : -32513.365  y : -1\n",
      "9  : 32513.362  y : 1\n",
      "Non invertible Matrix W \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-7a4c6c26f939>:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-u))\n",
      "<ipython-input-33-a1a37d995251>:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return m + np.multiply(y,1/sigmoid(-np.multiply(y,m)))\n",
      "<ipython-input-31-e4581f9ca835>:25: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  vect_neg_sqrt_W = 1/vect_sqrt_W # the negative square root of the original vector\n",
      "<ipython-input-31-e4581f9ca835>:26: RuntimeWarning: invalid value encountered in multiply\n",
      "  b = np.multiply(vect_sqrt_W,y)\n",
      "<ipython-input-31-e4581f9ca835>:28: RuntimeWarning: invalid value encountered in multiply\n",
      "  A = np.multiply(vect_neg_sqrt_W,big_mat)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5740bd7746d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#def fit_KLR_IRLS(mat_K, lam, y, max_iter = 10):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0malpha_KLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_KLR_IRLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_K\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mf_KLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_from_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_KLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGaussianKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-5740bd7746d5>\u001b[0m in \u001b[0;36mfit_KLR_IRLS\u001b[0;34m(mat_K, lam, y, max_iter)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_WKRR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_K\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_K\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-e4581f9ca835>\u001b[0m in \u001b[0;36mfit_WKRR\u001b[0;34m(mat_K, vect_W, lam, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mbig_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect_sqrt_W\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmat_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvect_sqrt_W\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect_neg_sqrt_W\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbig_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mvect_W_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_K\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#/mat_K.shape[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b, sym_pos, lower, overwrite_a, overwrite_b, debug, check_finite, assume_a, transposed)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mb_is_1D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'masked arrays are not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mtoarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \"array must not contain infs or NaNs\")\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "def fit_KLR_IRLS(mat_K, lam, y, max_iter = 10): \n",
    "    '''\n",
    "    Fonction qui optimise la loss définie par la la Kernel Logistic Regression. \n",
    "    \n",
    "    args : \n",
    "            mat_K : Kernel Matrix that contains the information in the data (K_ij=K(x_i,x_j))\n",
    "            \n",
    "            lam : regularization factor \n",
    "            \n",
    "            y : the vector we train on. Must be -1 or 1 \n",
    "            \n",
    "            max_iter : the maximum number of iteration we are ready to do \n",
    "    returns : \n",
    "            the vector alpha optimized \n",
    "            alpha then needs to be transformed to a function in order to fit the data.\n",
    "    '''\n",
    "    alpha = np.zeros(mat_K.shape[0])\n",
    "    m = compute_m(mat_K,alpha)    \n",
    "    W = compute_W(m)\n",
    "    z = compute_z(y,m)\n",
    "    for i in range(max_iter): \n",
    "        alpha = fit_WKRR(mat_K,W,lam,z)\n",
    "        m = compute_m(mat_K,alpha)\n",
    "        W = compute_W(m)\n",
    "        z = compute_z(y,m)\n",
    "        f = f_from_alpha(alpha, GaussianKernel, X_train)\n",
    "        for i in range(10): \n",
    "            print(i ,' :',np.round(f(X_train[i,:]),3), ' y :', y_train[i])\n",
    "    return alpha\n",
    "\n",
    "\n",
    "\n",
    "#def fit_KLR_IRLS(mat_K, lam, y, max_iter = 10):\n",
    "alpha_KLR = fit_KLR_IRLS(mat_K, lam,y_train)  \n",
    "f_KLR = f_from_alpha(alpha_KLR, GaussianKernel, X_train)\n",
    "for i in range(10): \n",
    "        print(i ,' :',np.round(f_KLR(X_train[i,:]),3), ' y :', y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "answering-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "class estimator(): \n",
    "    def __init__(self , Kernel = GaussianKernel, lam = 1e-8, sig2 = 1 ): \n",
    "        self.Kernel = Kernel\n",
    "        self.lam = lam \n",
    "        self.sig2 = sig2 \n",
    "        self.mat_K = None \n",
    "        self.alpha = None \n",
    "        self.f = None \n",
    "        \n",
    "    def predict_proba(self,X): \n",
    "        if self.f == None : \n",
    "            print(\"Il faut d'abord fitter les données\")\n",
    "        else : \n",
    "            probs = np.empty(X.shape[0])\n",
    "            for i in range(X.shape[0]): \n",
    "                probs[i] = self.f(X[i,:])\n",
    "            return probs \n",
    "    \n",
    "    def predict(self,X): \n",
    "        if self.f == None : \n",
    "            print(\"Il faut d'abord fitter les données\")\n",
    "        else : \n",
    "            prob = self.predict_proba(X)\n",
    "            return prob>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "worldwide-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lam = 1e-8 est bien\n",
    "class KRR(): \n",
    "    def __init__(self , Kernel = GaussianKernel, lam = 1e-8, sig2 = 1 ): \n",
    "        self.Kernel = Kernel\n",
    "        self.lam = lam \n",
    "        self.sig2 = sig2 \n",
    "        self.mat_K = None \n",
    "        self.alpha = None \n",
    "        self.f = None \n",
    "        #self.vect_W = vect_W \n",
    "    def fit(self, X, y): \n",
    "        if self.Kernel == GaussianKernel : \n",
    "            self.mat_K = to_mat_K(X, self.Kernel,self.sig2)\n",
    "        self.alpha = fit_KRR(self.mat_K, self.lam, y)\n",
    "        self.f = f_from_alpha(self.alpha,self.Kernel,X)\n",
    "    \n",
    "    def predict_proba(self,X): \n",
    "        if self.f == None : \n",
    "            print(\"Il faut d'abord fitter les données\")\n",
    "        else : \n",
    "            probs = np.empty(X.shape[0])\n",
    "            for i in range(X.shape[0]): \n",
    "                probs[i] = self.f(X[i,:])\n",
    "            return probs \n",
    "    def predict(self,X): \n",
    "        if self.f == None : \n",
    "            print(\"Il faut d'abord fitter les données\")\n",
    "        else : \n",
    "            prob = self.predict_proba(X)\n",
    "            return prob>0.5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "thick-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLR(estimator): \n",
    "    def __init__(self , Kernel = GaussianKernel, \n",
    "                 lam = 1e-9 , sig2 = 1): \n",
    "        super().__init__(Kernel, lam, sig2)\n",
    "        \n",
    "    def fit(self,X,y,max_iter = 10): \n",
    "        if self.Kernel == GaussianKernel: \n",
    "            self.mat_K = to_mat_K(X,self.Kernel,self.sig2)\n",
    "        self.alpha = fit_KLR_IRLS(self.mat_K, self.lam, y,max_iter)\n",
    "        self.f = f_from_alpha(self.alpha,self.Kernel,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "equivalent-title",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha_KLR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-25a3055395f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WKRR :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluate_MSE_from_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_KLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha_KLR' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_MSE_from_alpha(alpha,X,y,lam,mat_K, Kernel = GaussianKernel):\n",
    "    '''\n",
    "    Function that computes the MSE of the vector computed alpha. \n",
    "    \n",
    "    args : \n",
    "            alpha : this is the final value we compute. We do not look directly for a function but for some \n",
    "            parameter that will completely determined the function. alpha is this parameter\n",
    "            X : training data \n",
    "            y : target data \n",
    "            lam : regularization factor\n",
    "            mat_K : Kernel Matrix that contains the information in the data (K_ij=K(x_i,x_j))\n",
    "            Kernel : the kernel we are using. Normally, mat_K has been computed with the kernel K\n",
    "            \n",
    "    returns : \n",
    "            the MSE of the data plus the regularization factor\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    f_alpha = f_from_alpha(alpha,Kernel,X)\n",
    "    loss = 0\n",
    "    for i in range(n): \n",
    "        loss+= (y[i]-f_alpha(X[i,:]))**2.0\n",
    "    loss/= n\n",
    "    print(' loss without regularization : ', np.round(loss,4)) \n",
    "    reg = lam*alpha@mat_K@alpha\n",
    "    print('regularization :', np.round(reg,4))\n",
    "    return loss + reg \n",
    "\n",
    "\n",
    "print('WKRR :',evaluate_MSE_from_alpha(alpha_KLR, X_train, y_train, lam, mat_K))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
